"""Governance page component - Audit logs, compliance, and model cards."""

import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import sqlite3
from pathlib import Path


def render():
    """Render governance and audit page."""

    st.title("‚öñÔ∏è Governance & Audit")
    st.markdown("Model compliance, audit trails, and governance metrics")

    # Tabs for different governance aspects
    tab1, tab2, tab3, tab4 = st.tabs([
        "Audit Log",
        "Model Cards",
        "Bias & Fairness",
        "Compliance"
    ])

    with tab1:
        render_audit_log()

    with tab2:
        render_model_cards()

    with tab3:
        render_bias_fairness()

    with tab4:
        render_compliance()


def render_audit_log():
    """Render audit log viewer."""

    st.markdown("### Audit Trail")

    # Filters
    col1, col2, col3 = st.columns(3)

    with col1:
        event_type = st.selectbox(
            "Event Type",
            ["All", "Model Training", "Model Promotion", "Drift Alert", "Inference", "Data Update"]
        )

    with col2:
        time_range = st.selectbox(
            "Time Range",
            ["Last 24 Hours", "Last 7 Days", "Last 30 Days", "All Time"]
        )

    with col3:
        model_filter = st.selectbox(
            "Model",
            ["All Models", "heart_disease", "readmission_regression"]
        )

    # Generate sample audit log data
    audit_data = generate_sample_audit_log()

    # Display audit log
    st.markdown("### Recent Events")

    for event in audit_data[:20]:  # Show last 20 events
        with st.expander(f"{event['timestamp']} - {event['event_type']} ({event['model']})"):
            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown("**Event Details:**")
                st.caption(f"ID: {event['id']}")
                st.caption(f"User: {event['user']}")
                st.caption(f"Model: {event['model']}")
                st.caption(f"Status: {event['status']}")

            with col2:
                st.markdown("**Description:**")
                st.write(event['description'])

                if event.get('metadata'):
                    st.markdown("**Metadata:**")
                    st.json(event['metadata'])

    # Export audit log
    st.markdown("---")
    if st.button("üì• Export Audit Log (CSV)"):
        df_audit = pd.DataFrame(audit_data)
        csv = df_audit.to_csv(index=False)
        st.download_button(
            label="Download CSV",
            data=csv,
            file_name=f"audit_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )


def render_model_cards():
    """Render model card viewer."""

    st.markdown("### Model Registry")

    # Get selected model
    model_name = st.session_state.get('global_model_name', 'heart_disease')

    st.info(f"Viewing model card for: **{model_name}**")

    # Model card tabs
    card_tab1, card_tab2, card_tab3, card_tab4 = st.tabs([
        "Overview",
        "Training Details",
        "Performance",
        "Ethical Considerations"
    ])

    with card_tab1:
        st.markdown("### Model Overview")

        st.markdown("""
        **Model Name:** Heart Disease Classification Model

        **Version:** 1.2.3

        **Purpose:** Predict the presence of heart disease in patients based on clinical measurements and demographics.

        **Intended Use:** Clinical decision support tool for cardiologists and primary care physicians.

        **Target Population:** Adult patients (ages 20-100) undergoing cardiac evaluation.

        **Last Updated:** 2025-10-15

        **Owner:** Data Science Team, Community Hospital
        """)

        # Model metadata
        st.markdown("### Model Metadata")

        metadata = pd.DataFrame({
            'Attribute': [
                'Algorithm',
                'Framework',
                'Training Data Size',
                'Features',
                'Output Type',
                'Deployment Date'
            ],
            'Value': [
                'XGBoost Classifier',
                'XGBoost 2.0.0',
                '1,000 patients',
                '13 clinical features',
                'Binary classification (0/1)',
                '2025-10-01'
            ]
        })

        st.table(metadata)

    with card_tab2:
        st.markdown("### Training Details")

        st.markdown("""
        **Training Methodology:**
        - 5-fold stratified cross-validation
        - Hyperparameter optimization using Hyperopt (50 iterations)
        - No SMOTE required (balanced dataset)

        **Hyperparameters:**
        - Max depth: 6
        - Learning rate: 0.1
        - Number of estimators: 100
        - Min child weight: 1
        - Gamma: 0.0
        - Subsample: 0.8
        - Colsample by tree: 0.8

        **Training Infrastructure:**
        - Platform: Local development environment
        - GPU: Not applicable (CPU training)
        - Training time: ~15 minutes
        - MLflow tracking: Enabled
        """)

        # Feature importance
        st.markdown("### Feature Importance")

        feature_importance = pd.DataFrame({
            'Feature': [
                'chest_pain_type', 'max_heart_rate', 'st_depression',
                'vessels', 'thalassemia', 'age', 'exercise_angina',
                'slope', 'cholesterol', 'resting_bp', 'sex',
                'resting_ecg', 'fasting_blood_sugar'
            ],
            'Importance': [
                0.18, 0.15, 0.13, 0.11, 0.10, 0.09, 0.08,
                0.06, 0.04, 0.03, 0.02, 0.01, 0.01
            ]
        }).sort_values('Importance', ascending=True)

        import plotly.express as px
        fig = px.barh(
            feature_importance,
            x='Importance',
            y='Feature',
            title='Feature Importance Scores'
        )
        st.plotly_chart(fig, use_container_width=True)

    with card_tab3:
        st.markdown("### Model Performance")

        # Performance metrics
        perf_metrics = pd.DataFrame({
            'Metric': [
                'ROC-AUC', 'Accuracy', 'Precision', 'Recall',
                'F1-Score', 'MCC', 'Specificity'
            ],
            'Value': [0.8823, 0.8333, 0.8421, 0.8000, 0.8205, 0.6667, 0.8571],
            'Threshold': [0.80, 0.75, 0.70, 0.70, 0.70, 0.60, 0.70],
            'Status': ['‚úÖ', '‚úÖ', '‚úÖ', '‚úÖ', '‚úÖ', '‚úÖ', '‚úÖ']
        })

        st.table(perf_metrics.style.format({'Value': '{:.4f}', 'Threshold': '{:.2f}'}))

        # Performance over time
        st.markdown("**Performance Stability (Last 30 Days):**")
        st.success("Model performance has remained stable within acceptable thresholds.")

        # Limitations
        st.markdown("### Known Limitations")
        st.warning("""
        - **Limited to UCI Heart Disease features**: Model does not include genetic markers or advanced imaging data
        - **Training data size**: Relatively small dataset (1,000 patients)
        - **Geographic bias**: Training data may not represent all populations
        - **Temporal validity**: Model performance should be monitored for data drift
        """)

    with card_tab4:
        st.markdown("### Ethical Considerations")

        st.markdown("#### Fairness Assessment")

        fairness_metrics = pd.DataFrame({
            'Protected Attribute': ['Sex', 'Age Group'],
            'Demographic Parity': [0.08, 0.06],
            'Equal Opportunity': [0.06, 0.05],
            'Predictive Parity': [0.07, 0.04],
            'Status': ['‚úÖ Fair', '‚úÖ Fair']
        })

        st.table(fairness_metrics.style.format({
            'Demographic Parity': '{:.2f}',
            'Equal Opportunity': '{:.2f}',
            'Predictive Parity': '{:.2f}'
        }))

        st.caption("Threshold: 0.10 (all metrics below threshold)")

        st.markdown("#### Privacy & Security")

        st.info("""
        - **Data privacy**: All patient data is de-identified
        - **HIPAA compliance**: System follows HIPAA guidelines for PHI
        - **Access control**: Role-based access to model and predictions
        - **Audit logging**: All predictions and access logged
        """)

        st.markdown("#### Potential Risks")

        st.warning("""
        - **Not a replacement for clinical judgment**: Model outputs should be reviewed by qualified clinicians
        - **False negatives**: Model may miss some positive cases (recall = 80%)
        - **Over-reliance**: Clinicians should not rely solely on model predictions
        - **Distribution shift**: Performance may degrade if patient population changes
        """)

        st.markdown("#### Ethical Use Guidelines")

        st.markdown("""
        1. **Clinical oversight**: All predictions must be reviewed by licensed healthcare providers
        2. **Patient consent**: Patients should be informed when AI is used in their care
        3. **Transparency**: Explain model predictions to patients using SHAP values
        4. **Monitoring**: Continuously monitor for bias and performance degradation
        5. **Human in the loop**: Final decisions must be made by healthcare professionals
        """)


def render_bias_fairness():
    """Render bias and fairness analysis."""

    st.markdown("### Bias & Fairness Monitoring")

    # Overall fairness status
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown('<div class="success-card">', unsafe_allow_html=True)
        st.metric("Fairness Status", "‚úÖ Pass", delta=None)
        st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        st.metric("Protected Attributes", "2", delta=None)

    with col3:
        st.metric("Last Assessment", "2 days ago", delta=None)

    st.markdown("---")

    # Bias metrics by protected attribute
    st.markdown("### Bias Metrics by Protected Attribute")

    # Sex-based fairness
    st.markdown("#### Sex (Gender)")

    sex_metrics = pd.DataFrame({
        'Group': ['Female (0)', 'Male (1)'],
        'Sample Size': [480, 520],
        'Positive Rate': [0.35, 0.42],
        'TPR (Recall)': [0.78, 0.82],
        'PPV (Precision)': [0.84, 0.84],
        'Accuracy': [0.83, 0.84]
    })

    st.table(sex_metrics.style.format({
        'Positive Rate': '{:.2%}',
        'TPR (Recall)': '{:.2%}',
        'PPV (Precision)': '{:.2%}',
        'Accuracy': '{:.2%}'
    }))

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Demographic Parity", "0.07", help="Difference in positive rates")
    with col2:
        st.metric("Equal Opportunity", "0.04", help="Difference in TPR")
    with col3:
        st.metric("Predictive Parity", "0.00", help="Difference in PPV")

    st.markdown("---")

    # Age-based fairness
    st.markdown("#### Age Group")

    age_metrics = pd.DataFrame({
        'Group': ['Young (<40)', 'Middle (40-60)', 'Senior (>60)'],
        'Sample Size': [280, 420, 300],
        'Positive Rate': [0.32, 0.38, 0.45],
        'TPR (Recall)': [0.76, 0.80, 0.82],
        'PPV (Precision)': [0.82, 0.85, 0.84],
        'Accuracy': [0.81, 0.83, 0.84]
    })

    st.table(age_metrics.style.format({
        'Positive Rate': '{:.2%}',
        'TPR (Recall)': '{:.2%}',
        'PPV (Precision)': '{:.2%}',
        'Accuracy': '{:.2%}'
    }))

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Demographic Parity", "0.13", help="Max difference in positive rates")
    with col2:
        st.metric("Equal Opportunity", "0.06", help="Max difference in TPR")
    with col3:
        st.metric("Predictive Parity", "0.03", help="Max difference in PPV")

    st.markdown("---")

    # Fairness thresholds
    st.markdown("### Fairness Thresholds")

    st.info("""
    **Configured Thresholds:**
    - Demographic Parity: ‚â§ 0.10 (10%)
    - Equal Opportunity: ‚â§ 0.10 (10%)
    - Predictive Parity: ‚â§ 0.10 (10%)

    **Current Status:** All protected attributes pass fairness checks
    """)


def render_compliance():
    """Render compliance checklist."""

    st.markdown("### Compliance Checklist")

    compliance_items = [
        {"category": "Data Privacy", "item": "HIPAA compliance verified", "status": "‚úÖ"},
        {"category": "Data Privacy", "item": "Patient data de-identified", "status": "‚úÖ"},
        {"category": "Data Privacy", "item": "Access controls implemented", "status": "‚úÖ"},
        {"category": "Model Governance", "item": "Model card created", "status": "‚úÖ"},
        {"category": "Model Governance", "item": "Training data documented", "status": "‚úÖ"},
        {"category": "Model Governance", "item": "Feature definitions documented", "status": "‚úÖ"},
        {"category": "Fairness", "item": "Bias assessment completed", "status": "‚úÖ"},
        {"category": "Fairness", "item": "Protected attributes analyzed", "status": "‚úÖ"},
        {"category": "Fairness", "item": "Fairness thresholds met", "status": "‚úÖ"},
        {"category": "Monitoring", "item": "Drift detection enabled", "status": "‚úÖ"},
        {"category": "Monitoring", "item": "Performance monitoring active", "status": "‚úÖ"},
        {"category": "Monitoring", "item": "Audit logging enabled", "status": "‚úÖ"},
        {"category": "Security", "item": "Model artifacts secured", "status": "‚úÖ"},
        {"category": "Security", "item": "API authentication enabled", "status": "‚ö†Ô∏è"},
        {"category": "Security", "item": "Encryption at rest", "status": "‚ö†Ô∏è"},
    ]

    # Group by category
    categories = {}
    for item in compliance_items:
        cat = item['category']
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(item)

    # Display by category
    for category, items in categories.items():
        with st.expander(f"**{category}** ({sum(1 for i in items if i['status'] == '‚úÖ')}/{len(items)} complete)"):
            for item in items:
                col1, col2 = st.columns([6, 1])
                with col1:
                    st.write(item['item'])
                with col2:
                    st.write(item['status'])

    # Overall compliance score
    st.markdown("---")
    total_items = len(compliance_items)
    completed_items = sum(1 for item in compliance_items if item['status'] == '‚úÖ')
    compliance_pct = completed_items / total_items * 100

    st.markdown(f"### Overall Compliance Score: {compliance_pct:.0f}%")
    st.progress(compliance_pct / 100)

    if compliance_pct >= 90:
        st.success("Excellent compliance! System meets most requirements.")
    elif compliance_pct >= 75:
        st.warning("Good compliance. Address remaining items to achieve full compliance.")
    else:
        st.error("Compliance needs improvement. Address missing items.")


def generate_sample_audit_log():
    """Generate sample audit log data."""

    events = []
    event_types = [
        "Model Training",
        "Model Promotion",
        "Drift Alert",
        "Inference",
        "Data Update"
    ]

    for i in range(50):
        timestamp = datetime.now() - timedelta(hours=i*2)
        event_type = event_types[i % len(event_types)]

        event = {
            'id': f"AUD-{1000+i}",
            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
            'event_type': event_type,
            'model': 'heart_disease' if i % 3 != 0 else 'readmission_regression',
            'user': 'system' if i % 4 != 0 else 'data-scientist-1',
            'status': '‚úÖ Success',
            'description': f"Sample event description for {event_type}",
            'metadata': {
                'run_id': f"run-{i}",
                'version': '1.2.3'
            } if i % 5 == 0 else None
        }

        events.append(event)

    return events
